{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Copy of Neural Network_Traffic.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayushhendre/AI/blob/master/Copy_of_Neural_Network_Traffic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJZ75QnkAf7y"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "EPOCHS = 10\n",
        "IMG_WIDTH = 30\n",
        "IMG_HEIGHT = 30\n",
        "NUM_CATEGORIES = 43\n",
        "TEST_SIZE = 0.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kC4vrbzGAf71"
      },
      "source": [
        "def main():\n",
        "\n",
        "    # Get image arrays and labels for all image files\n",
        "    images, labels = load_data(data_dir)\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    labels = tf.keras.utils.to_categorical(labels)\n",
        "    x_train, x_test, y_train, y_test = train_test_split(\n",
        "        np.array(images), np.array(labels), test_size=TEST_SIZE\n",
        "    )\n",
        "\n",
        "    # Get a compiled neural network\n",
        "    model = get_model()\n",
        "\n",
        "    # Fit model on training data\n",
        "    model.fit(x_train, y_train, epochs=EPOCHS)\n",
        "\n",
        "    # Evaluate neural network performance\n",
        "    model.evaluate(x_test,  y_test, verbose=2)\n",
        "\n",
        "    # Save model to file\n",
        "    if len(sys.argv) == 3:\n",
        "        filename = sys.argv[2]\n",
        "        model.save(filename)\n",
        "        print(f\"Model saved to {filename}.\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QG-t-g9gAf73"
      },
      "source": [
        "def load_data(data_dir):\n",
        "    \n",
        "    # Initialise lists of images and labels\n",
        "    images = []\n",
        "    labels = []\n",
        "    data_dir=(r\"C:\\Users\\Legion\\Desktop\\gtsrb\")\n",
        "    # Loop through all files of all folders inside data_dir\n",
        "    for root, _, files in os.walk(data_dir):\n",
        "        for file in files:\n",
        "            if not file.startswith('.'):\n",
        "                # Read in and resize image\n",
        "                img = cv2.imread(os.path.join(root, file))\n",
        "                img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
        "\n",
        "                # Add current image and label to output lists\n",
        "                images.append(img)\n",
        "                labels.append(int(os.path.basename(root)))\n",
        "\n",
        "    return (images, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdNIepZ4Af75"
      },
      "source": [
        "def get_model():\n",
        "    \n",
        "     # Create a convolutional neural network\n",
        "    model = tf.keras.models.Sequential([\n",
        "\n",
        "        # Convolutional layer. Learn 32 filters using a 3x3 kernel\n",
        "        tf.keras.layers.Conv2D(\n",
        "            32, (3, 3), activation=\"relu\", input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)\n",
        "        ),\n",
        "\n",
        "        # Max-pooling layer, using 2x2 pool size\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        # 2nd convolutional layer. Learn 32 filters using a 3x3 kernel\n",
        "        tf.keras.layers.Conv2D(\n",
        "            32, (3, 3), activation=\"relu\", input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)\n",
        "        ),\n",
        "\n",
        "        # Flatten units\n",
        "        tf.keras.layers.Flatten(),\n",
        "\n",
        "        # Add a hidden layer with dropout\n",
        "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "\n",
        "        # Add an output layer with output unit for all categories\n",
        "        tf.keras.layers.Dense(NUM_CATEGORIES, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    # Train neural network\n",
        "    model.compile(\n",
        "        optimizer=\"adam\",\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IpwUqH5Af78",
        "outputId": "0edf103c-2758-435e-a43f-8fc392eca994"
      },
      "source": [
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "500/500 [==============================] - 7s 14ms/step - loss: 2.5695 - accuracy: 0.4565\n",
            "Epoch 2/10\n",
            "500/500 [==============================] - 7s 13ms/step - loss: 0.7841 - accuracy: 0.7821\n",
            "Epoch 3/10\n",
            "500/500 [==============================] - 7s 14ms/step - loss: 0.4971 - accuracy: 0.8590\n",
            "Epoch 4/10\n",
            "500/500 [==============================] - 8s 15ms/step - loss: 0.3577 - accuracy: 0.8958\n",
            "Epoch 5/10\n",
            "500/500 [==============================] - 10s 19ms/step - loss: 0.2953 - accuracy: 0.9153\n",
            "Epoch 6/10\n",
            "500/500 [==============================] - 9s 19ms/step - loss: 0.2649 - accuracy: 0.9235\n",
            "Epoch 7/10\n",
            "500/500 [==============================] - 9s 19ms/step - loss: 0.2440 - accuracy: 0.9307\n",
            "Epoch 8/10\n",
            "500/500 [==============================] - 9s 19ms/step - loss: 0.2297 - accuracy: 0.9374\n",
            "Epoch 9/10\n",
            "500/500 [==============================] - 8s 17ms/step - loss: 0.2023 - accuracy: 0.9424\n",
            "Epoch 10/10\n",
            "500/500 [==============================] - 9s 17ms/step - loss: 0.1910 - accuracy: 0.9464\n",
            "333/333 - 1s - loss: 0.1541 - accuracy: 0.9708\n",
            "WARNING:tensorflow:From C:\\Users\\Legion\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From C:\\Users\\Legion\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FailedPreconditionError",
          "evalue": "C:\\Users\\Legion\\AppData\\Roaming\\jupyter\\runtime\\kernel-4d4ae433-c837-4631-9317-d4a9947ee3e1.json is not a directory",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-42-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-39-0046e5610cec>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Model saved to {filename}.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[0;32m   1977\u001b[0m     \"\"\"\n\u001b[0;32m   1978\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[1;32m-> 1979\u001b[1;33m                     signatures, options)\n\u001b[0m\u001b[0;32m   1980\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1981\u001b[0m   def save_weights(self,\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[0;32m    132\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n\u001b[1;32m--> 134\u001b[1;33m                           signatures, options)\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\save.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(model, filepath, overwrite, include_optimizer, signatures, options)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;31m# we use the default replica context here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mdistribution_strategy_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_default_replica_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m       \u001b[0msave_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\save.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[0;32m    979\u001b[0m   \u001b[1;31m# Write the checkpoint, copy assets into the assets directory, and write out\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m   \u001b[1;31m# the SavedModel proto itself.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 981\u001b[1;33m   \u001b[0mutils_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_or_create_variables_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    982\u001b[0m   ckpt_options = checkpoint_options.CheckpointOptions(\n\u001b[0;32m    983\u001b[0m       experimental_io_device=options.experimental_io_device)\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\utils_impl.py\u001b[0m in \u001b[0;36mget_or_create_variables_dir\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m    212\u001b[0m   \u001b[0mvariables_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_variables_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfile_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile_exists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariables_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m     \u001b[0mfile_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursive_create_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariables_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mvariables_dir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mrecursive_create_dir\u001b[1;34m(dirname)\u001b[0m\n\u001b[0;32m    463\u001b[0m     \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mfails\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m   \"\"\"\n\u001b[1;32m--> 465\u001b[1;33m   \u001b[0mrecursive_create_dir_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mrecursive_create_dir_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    478\u001b[0m     \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mfails\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m   \"\"\"\n\u001b[1;32m--> 480\u001b[1;33m   \u001b[0m_pywrap_file_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRecursivelyCreateDir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mFailedPreconditionError\u001b[0m: C:\\Users\\Legion\\AppData\\Roaming\\jupyter\\runtime\\kernel-4d4ae433-c837-4631-9317-d4a9947ee3e1.json is not a directory"
          ]
        }
      ]
    }
  ]
}